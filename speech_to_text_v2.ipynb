{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U openai-whisper\n",
    "%pip install pyannote.audio\n",
    "%pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import subprocess\n",
    "import subprocess\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MP3 into WAV\n",
    "Run the first two lines if you are using a virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = \"C:\\\\ProgramData\\\\ffmpeg\"\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path\n",
    "\n",
    "def mp3_to_wav(folder_path):\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file is an MP3\n",
    "        if file_name.endswith(\".mp3\"):\n",
    "            # Set the paths for the MP3 and WAV files\n",
    "            mp3_path = os.path.join(folder_path, file_name)\n",
    "            wav_path = os.path.join(folder_path, file_name[:-4] + \".wav\")\n",
    "            \n",
    "            # Use subprocess to run the ffmpeg command to convert the MP3 to WAV\n",
    "            subprocess.run([\"ffmpeg\", \"-i\", mp3_path, \"-ar\", \"16000\", wav_path], check=True)\n",
    "            \n",
    "            # Delete the original MP3 file\n",
    "            os.remove(mp3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Whisper and Pyannote Audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_speakers = 2 #@param {type:\"integer\"}\n",
    "language = 'English' #@param ['any', 'English']\n",
    "model_size = \"large-v2\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large_v2\"]\n",
    "\n",
    "model_name = model_size\n",
    "if language == 'English' and model_size != 'medium':\n",
    "  model_name += '.en'\n",
    "\n",
    "model = whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(path, num_speakers=2,model=model):\n",
    "  result = model.transcribe(path)\n",
    "  output = result[\"text\"]\n",
    "  return output\n",
    "\n",
    "def write_file(text, file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "def process_transcript(transcript):\n",
    "    prompt = f\"Given the following transcript of a telemarketing call between two speakers, organize the utterances by alternating speakers, without the prefix Speaker 1 or Speaker 2:\\n{transcript}\\n\\nUtterances:\\n\" \n",
    "    response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.8,\n",
    ")\n",
    "    processed_transcript = response.choices[0].text.strip()\n",
    "    return processed_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = ['/do_not_call','/interested','/not_interested','/successful_sale','call_back']\n",
    "for classification in classifications:\n",
    "    audio_path = './asset/testing_audio' + classification\n",
    "    result_path = './asset/testing_result' + classification\n",
    "    mp3_to_wav(audio_path)\n",
    "    for file_name in os.listdir(audio_path):\n",
    "        file_path = os.path.join(audio_path, file_name)\n",
    "        file_result_path = os.path.join(result_path, file_name[:-4] + '.txt')\n",
    "        if not os.path.exists(file_result_path):\n",
    "            output =transcribe(file_path)\n",
    "            output = process_transcript(output)\n",
    "            write_file(output, file_result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
