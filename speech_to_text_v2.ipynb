{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U openai-whisper\n",
    "#%pip install pyannote.audio\n",
    "#%pip install openai\n",
    "\n",
    "#### Usually only works in terminal #### FOR GPU ####\n",
    "#pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import subprocess\n",
    "import subprocess\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs GPU if device has one\\n\n",
    "import torch\n",
    "#Check if CUDA-enabled GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MP3 into WAV\n",
    "Run the first two lines if you are using a virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffmpeg_path = \"C:\\\\PATH_Programs\\\\\"\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path\n",
    "\n",
    "def mp3_to_wav(folder_path):\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file is an MP3\n",
    "        if file_name.endswith(\".mp3\"):\n",
    "            # Set the paths for the MP3 and WAV files\n",
    "            mp3_path = os.path.join(folder_path, file_name)\n",
    "            wav_path = os.path.join(folder_path, file_name[:-4] + \".wav\")\n",
    "            \n",
    "            # Use subprocess to run the ffmpeg command to convert the MP3 to WAV\n",
    "            subprocess.run([\"ffmpeg\", \"-i\", mp3_path, \"-ar\", \"16000\", wav_path], check=True)\n",
    "            \n",
    "            # Delete the original MP3 file\n",
    "            os.remove(mp3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Whisper and Pyannote Audio model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_speakers = 2 #@param {type:\"integer\"}\n",
    "language = 'English' #@param ['any', 'English']\n",
    "model_size = \"large-v2\" #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large_v2\"]\n",
    "\n",
    "model_name = model_size\n",
    "if language == 'English' and model_size != 'medium':\n",
    "  model_name += '.en'\n",
    "\n",
    "model = whisper.load_model(model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "#Making sure the GPU is running\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(path, num_speakers=2,model=model):\n",
    "  result = model.transcribe(path)\n",
    "  output = result[\"text\"]\n",
    "  return output\n",
    "\n",
    "def write_file(text, file_path):\n",
    "    directory = os.path.dirname(file_path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(text)\n",
    "        \n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "def process_transcript(transcript):\n",
    "    prompt = f\"Given the following transcript of a telemarketing call between a Telemarketer and a Prospective Customer, your task is to organize the utterances by alternating speakers, using the prefix 'AI:' for the Telemarketer and 'Customer:' for the Prospective Customer. The purpose of the call is to ask the customer if they want to sell their property. Please provide the organized utterances in the same order as they appear in the transcript. If two speakers speak at the same time, please indicate this by placing their utterances on a new line. :\\n{transcript}\\n\\nUtterances:\\n\" \n",
    "    response = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.8,\n",
    ")\n",
    "    processed_transcript = response.choices[0].text.strip()\n",
    "    return processed_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications = ['/call_back', '/do_not_call', '/not_interested', '/successful_sale', '/wrong_number']\n",
    "for classification in classifications:\n",
    "    audio_path = './asset/testing_audio' + classification\n",
    "    result_path = './asset/testing_result' + classification\n",
    "    mp3_to_wav(audio_path)\n",
    "    for file_name in os.listdir(audio_path):\n",
    "        file_path = os.path.join(audio_path, file_name)\n",
    "        file_result_path = os.path.join(result_path, file_name[:-4] + '.txt')\n",
    "        if not os.path.exists(file_result_path):\n",
    "            output =transcribe(file_path)\n",
    "            output = process_transcript(output)\n",
    "            write_file(output, file_result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
